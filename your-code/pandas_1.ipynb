{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas Lab\n",
    "\n",
    "Complete the following set of exercises to solidify your knowledge of Pandas fundamentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Numpy and Pandas and alias them to `np` and `pd` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Pandas Series containing the elements of the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the list of numbers (I added this comment, list was given)\n",
    "\n",
    "lst = [5.7, 75.2, 74.4, 84.0, 66.5, 66.3, 55.8, 75.7, 29.1, 43.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5.7\n",
      "1    75.2\n",
      "2    74.4\n",
      "3    84.0\n",
      "4    66.5\n",
      "5    66.3\n",
      "6    55.8\n",
      "7    75.7\n",
      "8    29.1\n",
      "9    43.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Creating a Pandas Series from the list\n",
    "# A Series is like a 1-dimensional array with labels, where each element in the list\n",
    "# will be assigned an index (0 to 9, by default).\n",
    "series = pd.Series(lst)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**         | **Python List**                            | **Pandas Series**                          |\n",
    "|---------------------|--------------------------------------------|--------------------------------------------|\n",
    "\n",
    "| **Definition**      | A built-in Python data structure that     | A one-dimensional labeled array in the     |\n",
    "|                     | holds a collection of items.              | Pandas library.                            |\n",
    "\n",
    "| **Data Structure**  | Basic data structure in Python.           | Part of the Pandas library, specialized    |\n",
    "|                     |                                            | for data analysis.                         |\n",
    "\n",
    "| **Indexing**        | Implicit indexing (0, 1, 2, ...) but      | Explicitly indexed (default is 0, 1, 2,    |\n",
    "|                     | cannot have custom indices.               | ...), and you can define custom indices.   |\n",
    "\n",
    "| **Data Type**       | Can hold multiple data types in the       | Preferably holds a single data type (e.g., |\n",
    "|                     | same list (e.g., strings, integers,       | all floats or all strings). Mixed types    |\n",
    "|                     | floats).                                  | are possible but not ideal.                |\n",
    "\n",
    "| **Operations**      | Limited operations (must use loops or     | Optimized for mathematical and statistical |\n",
    "|                     | list comprehensions for many tasks).      | operations (applies functions directly to  |\n",
    "|                     |                                            | the data).                                 |\n",
    "\n",
    "| **Metadata**        | No metadata; just raw data.               | Contains metadata like index and data      |\n",
    "|                     |                                            | type (`dtype`).                            |\n",
    "\n",
    "| **Size**            | Limited by Python's list memory overhead. | More memory-efficient for numerical data.  |\n",
    "\n",
    "| **Performance**     | Slower for large-scale computations.      | Faster for large-scale data operations     |\n",
    "|                     |                                            | due to vectorization and underlying C      |\n",
    "|                     |                                            | implementation.                            |\n",
    "\n",
    "| **Flexibility**     | General-purpose collection.               | Designed specifically for data manipulation|\n",
    "|                     |                                            | and analysis.                              |\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Key Advantages of Pandas Series\n",
    "\n",
    "- **Label-Based Indexing:**\n",
    "  - Each element in a Pandas Series has an associated label (index), allowing intuitive and flexible data access and manipulation.\n",
    "\n",
    "- **Efficient Data Operations:**\n",
    "  - Supports vectorized operations, making computations faster and more concise compared to Python lists.\n",
    "\n",
    "- **Integration with Pandas DataFrames:**\n",
    "  - Works seamlessly with DataFrames, enabling complex data manipulation workflows.\n",
    "\n",
    "- **Handling Missing Data:**\n",
    "  - Handles missing or NaN values efficiently, allowing operations like filling or dropping missing data.\n",
    "\n",
    "- **Enhanced Metadata:**\n",
    "  - Stores additional information like the data type (`dtype`) and index, which simplifies debugging and data understanding.\n",
    "\n",
    "- **Compatibility with Libraries:**\n",
    "  - Easily integrates with other data manipulation and machine learning libraries, such as NumPy and scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "# When to Use Which?\n",
    "\n",
    "- **Use a Python List when:**\n",
    "  1. The data size is small.\n",
    "  2. Simple storage or iteration is needed.\n",
    "  3. No additional functionality like indexing or data manipulation is required.\n",
    "\n",
    "- **Use a Pandas Series when:**\n",
    "  1. The data is part of a larger data analysis task.\n",
    "  2. Operations like filtering, indexing, or mathematical computations are needed.\n",
    "  3. Integration with DataFrames or other Pandas structures is required.\n",
    "  4. Efficient handling of missing values is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use indexing to return the third value in the Series above.\n",
    "\n",
    "*Hint: Remember that indexing begins at 0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.4\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Use indexing to get the third value (index 2)\n",
    "third_value = series[2]\n",
    "\n",
    "# Print the third value\n",
    "print(third_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a Pandas DataFrame from the list of lists below. Each sublist should be represented as a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given list of lists (I added this)\n",
    "\n",
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4\n",
      "0  53.1  95.0  67.5  35.0  78.4\n",
      "1  61.3  40.8  30.8  37.8  87.6\n",
      "2  20.6  73.2  44.2  14.6  91.8\n",
      "3  57.4   0.1  96.1   4.2  69.5\n",
      "4  83.6  20.5  85.4  22.8  35.9\n",
      "5  49.0  69.0   0.1  31.8  89.1\n",
      "6  23.3  40.7  95.0  83.8  26.9\n",
      "7  27.6  26.4  53.8  88.8  68.5\n",
      "8  96.6  96.4  53.4  72.4  50.1\n",
      "9  73.7  39.0  43.2  81.6  34.7\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Create a DataFrame from the list of lists, each sublist becomes a row.\n",
    "df = pd.DataFrame(b)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Rename the data frame columns based on the names in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score 1  Score 2  Score 3  Score 4  Score 5\n",
      "0     53.1     95.0     67.5     35.0     78.4\n",
      "1     61.3     40.8     30.8     37.8     87.6\n",
      "2     20.6     73.2     44.2     14.6     91.8\n",
      "3     57.4      0.1     96.1      4.2     69.5\n",
      "4     83.6     20.5     85.4     22.8     35.9\n",
      "5     49.0     69.0      0.1     31.8     89.1\n",
      "6     23.3     40.7     95.0     83.8     26.9\n",
      "7     27.6     26.4     53.8     88.8     68.5\n",
      "8     96.6     96.4     53.4     72.4     50.1\n",
      "9     73.7     39.0     43.2     81.6     34.7\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Given list of column names\n",
    "column_names = [\"Score 1\", \"Score 2\", \"Score 3\", \"Score 4\", \"Score 5\"]\n",
    "\n",
    "# Rename the DataFrame columns using the provided list\n",
    "df.columns = column_names\n",
    "\n",
    "# Display the renamed DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a subset of this data frame that contains only the Score 1, 3, and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score 1  Score 3  Score 5\n",
      "0     53.1     67.5     78.4\n",
      "1     61.3     30.8     87.6\n",
      "2     20.6     44.2     91.8\n",
      "3     57.4     96.1     69.5\n",
      "4     83.6     85.4     35.9\n",
      "5     49.0      0.1     89.1\n",
      "6     23.3     95.0     26.9\n",
      "7     27.6     53.8     68.5\n",
      "8     96.6     53.4     50.1\n",
      "9     73.7     43.2     34.7\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Create a subset of the DataFrame with the specified columns\n",
    "subset_df = df[[\"Score 1\", \"Score 3\", \"Score 5\"]]\n",
    "\n",
    "# Display the subset DataFrame\n",
    "print(subset_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. From the original data frame, calculate the average Score_3 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score 3: 56.95000000000001\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Calculate the average of Score 3\n",
    "average_score_3 = df[\"Score 3\"].mean()\n",
    "\n",
    "# Display the result\n",
    "print(\"Average Score 3:\", average_score_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. From the original data frame, calculate the maximum Score_4 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Score 4: 88.8\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Calculate the maximum of Score 4\n",
    "max_score_4 = df[\"Score 4\"].max()\n",
    "\n",
    "# Display the result\n",
    "print(\"Maximum Score 4:\", max_score_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. From the original data frame, calculate the median Score 2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Score 2: 40.75\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Calculate the median of Score 2\n",
    "median_score_2 = df[\"Score 2\"].median()\n",
    "\n",
    "# Display the result\n",
    "print(\"Median Score 2:\", median_score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create a Pandas DataFrame from the dictionary of product orders below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {'Description': ['LUNCH BAG APPLE DESIGN',\n",
    "  'SET OF 60 VINTAGE LEAF CAKE CASES ',\n",
    "  'RIBBON REEL STRIPES DESIGN ',\n",
    "  'WORLD WAR 2 GLIDERS ASSTD DESIGNS',\n",
    "  'PLAYING CARDS JUBILEE UNION JACK',\n",
    "  'POPCORN HOLDER',\n",
    "  'BOX OF VINTAGE ALPHABET BLOCKS',\n",
    "  'PARTY BUNTING',\n",
    "  'JAZZ HEARTS ADDRESS BOOK',\n",
    "  'SET OF 4 SANTA PLACE SETTINGS'],\n",
    " 'Quantity': [1, 24, 1, 2880, 2, 7, 1, 4, 10, 48],\n",
    " 'UnitPrice': [1.65, 0.55, 1.65, 0.18, 1.25, 0.85, 11.95, 4.95, 0.19, 1.25],\n",
    " 'Revenue': [1.65, 13.2, 1.65, 518.4, 2.5, 5.95, 11.95, 19.8, 1.9, 60.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Description  Quantity  UnitPrice  Revenue\n",
      "0              LUNCH BAG APPLE DESIGN         1       1.65     1.65\n",
      "1  SET OF 60 VINTAGE LEAF CAKE CASES         24       0.55    13.20\n",
      "2         RIBBON REEL STRIPES DESIGN          1       1.65     1.65\n",
      "3   WORLD WAR 2 GLIDERS ASSTD DESIGNS      2880       0.18   518.40\n",
      "4    PLAYING CARDS JUBILEE UNION JACK         2       1.25     2.50\n",
      "5                      POPCORN HOLDER         7       0.85     5.95\n",
      "6      BOX OF VINTAGE ALPHABET BLOCKS         1      11.95    11.95\n",
      "7                       PARTY BUNTING         4       4.95    19.80\n",
      "8            JAZZ HEARTS ADDRESS BOOK        10       0.19     1.90\n",
      "9       SET OF 4 SANTA PLACE SETTINGS        48       1.25    60.00\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_orders = pd.DataFrame(orders)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calculate the total quantity ordered and revenue generated from these orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Quantity Ordered: 2978\n",
      "Total Revenue Generated: $637.00\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "#Calculate total quantity and revenue\n",
    "total_quantity = df_orders['Quantity'].sum()\n",
    "total_revenue = df_orders['Revenue'].sum()\n",
    "\n",
    "print(f\"Total Quantity Ordered: {total_quantity}\")\n",
    "print(f\"Total Revenue Generated: ${total_revenue:.2f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### What does `.2f` mean?\n",
    "\n",
    "The `.2f` in Python's string formatting specifies that a floating-point number should be displayed with **2 digits after the decimal point**. Here's a breakdown:\n",
    "\n",
    "- **`.`**: Indicates that you're specifying the precision of the number.\n",
    "- **`2`**: The number of digits to include after the decimal point.\n",
    "- **`f`**: Stands for \"fixed-point notation,\" which is the standard way to represent floating-point numbers (e.g., `123.45`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Obtain the prices of the most expensive and least expensive items ordered and print the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Expensive Item Price: $11.95\n",
      "Least Expensive Item Price: $0.18\n",
      "Price Difference: $11.77\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "#Most expensive and least expensive items\n",
    "most_expensive_price = df_orders['UnitPrice'].max()\n",
    "least_expensive_price = df_orders['UnitPrice'].min()\n",
    "\n",
    "price_difference = most_expensive_price - least_expensive_price\n",
    "\n",
    "print(f\"Most Expensive Item Price: ${most_expensive_price:.2f}\")\n",
    "print(f\"Least Expensive Item Price: ${least_expensive_price:.2f}\")\n",
    "print(f\"Price Difference: ${price_difference:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load another dataset for more exercisesÂº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "admissions = pd.read_csv('../Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the dataset by looking at the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "0           1        337          118                  4  4.5   4.5  9.65   \n",
      "1           2        316          104                  3  3.0   3.5  8.00   \n",
      "2           3        322          110                  3  3.5   2.5  8.67   \n",
      "3           4        314          103                  2  2.0   3.0  8.21   \n",
      "4           5        330          115                  5  4.5   3.0  9.34   \n",
      "\n",
      "   Research  Chance of Admit   \n",
      "0         1              0.92  \n",
      "1         1              0.72  \n",
      "2         1              0.80  \n",
      "3         0              0.65  \n",
      "4         1              0.90  \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Before beginning to work with this dataset and evaluating graduate admissions data, we will verify that there is no missing data in the dataset. Do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial No.           0\n",
      "GRE Score            0\n",
      "TOEFL Score          0\n",
      "University Rating    0\n",
      "SOP                  0\n",
      "LOR                  0\n",
      "CGPA                 0\n",
      "Research             0\n",
      "Chance of Admit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Check for missing data\n",
    "missing_data = admissions.isnull().sum()\n",
    "\n",
    "# Display the number of missing values in each column\n",
    "print(missing_data)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* admissions.isnull(): This function returns a DataFrame of the same shape as the original one, with True where there is missing data and False where there is not.\n",
    "\n",
    "* .sum(): This counts the True values in each column, effectively giving you the number of missing values per column.\n",
    "\n",
    "* If the output shows zeros for all columns, it means there is no missing data in the dataset.\n",
    "\n",
    "* If any column has a value greater than 0, that column contains missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2 -  Interestingly, there is a column that uniquely identifies the applicants. This column is the serial number column. Instead of having our own index, we should make this column our index. Do this in the cell below. Keep the column in the dataframe in addition to making it an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "Serial No.                                                               \n",
      "1                 337          118                  4  4.5   4.5  9.65   \n",
      "2                 316          104                  3  3.0   3.5  8.00   \n",
      "3                 322          110                  3  3.5   2.5  8.67   \n",
      "4                 314          103                  2  2.0   3.0  8.21   \n",
      "5                 330          115                  5  4.5   3.0  9.34   \n",
      "\n",
      "            Research  Chance of Admit   \n",
      "Serial No.                              \n",
      "1                  1              0.92  \n",
      "2                  1              0.72  \n",
      "3                  1              0.80  \n",
      "4                  0              0.65  \n",
      "5                  1              0.90  \n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "admissions.set_index('Serial No.', inplace=True)\n",
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* admissions.set_index('Serial No.', inplace=True): This function sets the \"Serial No.\" column as the index of the DataFrame, but since inplace=True is used, it modifies the original DataFrame directly.\n",
    "\n",
    "* After making the \"Serial No.\" column the index, it is still kept in the DataFrame because it is not removed. The column will appear as part of the DataFrame, but it will also be the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that `GRE Score` and `CGPA` also uniquely identify the data. Show this in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Cell above doesn't make sense to me. I'm changing it\n",
    "\n",
    "\"Additionally, let's verify whether 'GRE Score' and 'CGPA' uniquely identify rows in the dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do GRE Score and CGPA uniquely identify the data? True\n"
     ]
    }
   ],
   "source": [
    "#I added this cell\n",
    "\n",
    "# your code here\n",
    "\n",
    "is_unique = admissions.duplicated(subset=['GRE Score', 'CGPA']).sum() == 0\n",
    "print(f\"Do GRE Score and CGPA uniquely identify the data? {is_unique}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* admissions.duplicated(subset=['GRE Score', 'CGPA']):\n",
    "\n",
    "    * Checks for duplicate rows based on the specified columns (GRE Score and CGPA).\n",
    "    * Returns a boolean Series where True indicates a duplicate and False indicates a unique combination of GRE Score and CGPA.\n",
    "\n",
    "* .sum():\n",
    "\n",
    "    * Counts the number of True values in the resulting boolean Series, which corresponds to the number of duplicate rows.\n",
    "\n",
    "* == 0:\n",
    "\n",
    "    * Compares the sum of duplicates to 0. If there are no duplicates, the condition evaluates to True, meaning the columns uniquely identify the data.\n",
    "\n",
    "* is_unique:\n",
    "\n",
    "    * Stores the result (True or False) indicating whether GRE Score and CGPA uniquely identify the data.\n",
    "\n",
    "* print(f\"...\"):\n",
    "\n",
    "    * Prints the result in a formatted string, stating whether the combination of GRE Score and CGPA is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - In this part of the lab, we would like to test complex conditions on the entire data set at once. Let's start by finding the number of rows where the CGPA is greater than 9 and the student has performed an investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where CGPA > 9 and Research == 1:\n",
      "            GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "Serial No.                                                               \n",
      "1                 337          118                  4  4.5   4.5  9.65   \n",
      "5                 330          115                  5  4.5   3.0  9.34   \n",
      "11                328          112                  4  4.0   4.5  9.10   \n",
      "20                328          116                  5  5.0   5.0  9.50   \n",
      "21                334          119                  5  5.0   4.5  9.70   \n",
      "...               ...          ...                ...  ...   ...   ...   \n",
      "380               329          111                  4  4.5   4.0  9.23   \n",
      "381               324          110                  3  3.5   3.5  9.04   \n",
      "382               325          107                  3  3.0   3.5  9.11   \n",
      "383               330          116                  4  5.0   4.5  9.45   \n",
      "385               333          117                  4  5.0   4.0  9.66   \n",
      "\n",
      "            Research  Chance of Admit   \n",
      "Serial No.                              \n",
      "1                  1              0.92  \n",
      "5                  1              0.90  \n",
      "11                 1              0.78  \n",
      "20                 1              0.94  \n",
      "21                 1              0.95  \n",
      "...              ...               ...  \n",
      "380                1              0.89  \n",
      "381                1              0.82  \n",
      "382                1              0.84  \n",
      "383                1              0.91  \n",
      "385                1              0.95  \n",
      "\n",
      "[101 rows x 8 columns]\n",
      "\n",
      "Number of rows where CGPA > 9 and Research == 1: 101\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where CGPA > 9 and Research == 1\n",
    "cgpa_research_filter = (admissions['CGPA'] > 9) & (admissions['Research'] == 1)\n",
    "\n",
    "# Display filtered rows for clarity\n",
    "filtered_rows = admissions[cgpa_research_filter]\n",
    "print(\"Rows where CGPA > 9 and Research == 1:\")\n",
    "print(filtered_rows)\n",
    "\n",
    "# Count the number of rows matching the condition\n",
    "count = filtered_rows.shape[0]\n",
    "print(f\"\\nNumber of rows where CGPA > 9 and Research == 1: {count}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* cgpa_research_filter = (admissions['CGPA'] > 9) & (admissions['Research'] == 1):\n",
    "\n",
    "    *  This creates a filter using two conditions:\n",
    "        * admissions['CGPA'] > 9: Selects rows where CGPA is greater \n",
    "           than 9.\n",
    "        * admissions['Research'] == 1: Selects rows where the student has \n",
    "          performed research (indicated by a value of 1 in the Research \n",
    "          column).\n",
    "\n",
    "    *  The & operator ensures that both conditions must be true for a row \n",
    "       to be included in the filter.\n",
    "\n",
    "* filtered_rows = admissions[cgpa_research_filter]:\n",
    "\n",
    "    *  Applies the filter to the dataset to extract rows where both \n",
    "       conditions are satisfied.\n",
    "    *  Creates a new DataFrame, filtered_rows, containing only these rows.\n",
    "\n",
    "* filtered_rows.shape[0]:\n",
    "\n",
    "    *  Counts the total number of rows in the filtered DataFrame, \n",
    "       representing the number of applicants who meet the criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Now return all the rows where the CGPA is greater than 9 and the SOP score is less than 3.5. Find the mean chance of admit for these applicants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where CGPA > 9 and SOP < 3.5:\n",
      "            GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "Serial No.                                                               \n",
      "29                338          118                  4  3.0   4.5  9.40   \n",
      "63                327          114                  3  3.0   3.0  9.02   \n",
      "141               326          114                  3  3.0   3.0  9.11   \n",
      "218               324          111                  4  3.0   3.0  9.01   \n",
      "382               325          107                  3  3.0   3.5  9.11   \n",
      "\n",
      "            Research  Chance of Admit   \n",
      "Serial No.                              \n",
      "29                 1              0.91  \n",
      "63                 0              0.61  \n",
      "141                1              0.83  \n",
      "218                1              0.82  \n",
      "382                1              0.84  \n",
      "\n",
      "Mean chance of admit for these applicants: 0.80\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Filter rows where CGPA > 9 and SOP < 3.5\n",
    "filtered_rows = admissions[(admissions['CGPA'] > 9) & (admissions['SOP'] < 3.5)]\n",
    "\n",
    "# Calculate the mean Chance of Admit\n",
    "mean_chance = filtered_rows['Chance of Admit '].mean()\n",
    "\n",
    "print(\"Rows where CGPA > 9 and SOP < 3.5:\")\n",
    "print(filtered_rows)\n",
    "print(f\"\\nMean chance of admit for these applicants: {mean_chance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* admissions[(admissions['CGPA'] > 9) & (admissions['SOP'] < 3.5)]:\n",
    "\n",
    "    * Filters the dataset to include only rows where:\n",
    "\n",
    "        1. admissions['CGPA'] > 9: CGPA is greater than 9.\n",
    "\n",
    "        2. admissions['SOP'] < 3.5: SOP score is less than 3.5.\n",
    "    \n",
    "    * The & operator ensures that both conditions must be true for a row \n",
    "      to be included.\n",
    "\n",
    "* filtered_rows['Chance of Admit '].mean():\n",
    "\n",
    "    * Calculates the mean of the Chance of Admit column for the filtered \n",
    "      rows.\n",
    "\n",
    "* print(filtered_rows): Displays all rows that meet the conditions.\n",
    "print(f\"...\"):\n",
    "\n",
    "* Outputs the mean chance of admit with a formatted result rounded to two \n",
    "  decimal places (.2f)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
