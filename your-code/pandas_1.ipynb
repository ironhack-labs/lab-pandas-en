{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas Lab\n",
    "\n",
    "Complete the following set of exercises to solidify your knowledge of Pandas fundamentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Numpy and Pandas and alias them to `np` and `pd` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Pandas Series containing the elements of the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [5.7, 75.2, 74.4, 84.0, 66.5, 66.3, 55.8, 75.7, 29.1, 43.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5.7\n",
      "1    75.2\n",
      "2    74.4\n",
      "3    84.0\n",
      "4    66.5\n",
      "5    66.3\n",
      "6    55.8\n",
      "7    75.7\n",
      "8    29.1\n",
      "9    43.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Creates a pandas series with the elements provided for lst.\n",
    "series = pd.Series(lst)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use indexing to return the third value in the Series above.\n",
    "\n",
    "*Hint: Remember that indexing begins at 0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.4\n"
     ]
    }
   ],
   "source": [
    "# Uses indexing to return the third value in the series created in the previous step.\n",
    "print(series[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a Pandas DataFrame from the list of lists below. Each sublist should be represented as a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4\n",
      "0  53.1  95.0  67.5  35.0  78.4\n",
      "1  61.3  40.8  30.8  37.8  87.6\n",
      "2  20.6  73.2  44.2  14.6  91.8\n",
      "3  57.4   0.1  96.1   4.2  69.5\n",
      "4  83.6  20.5  85.4  22.8  35.9\n",
      "5  49.0  69.0   0.1  31.8  89.1\n",
      "6  23.3  40.7  95.0  83.8  26.9\n",
      "7  27.6  26.4  53.8  88.8  68.5\n",
      "8  96.6  96.4  53.4  72.4  50.1\n",
      "9  73.7  39.0  43.2  81.6  34.7\n"
     ]
    }
   ],
   "source": [
    "# Creates a pandas data frame from the list in b.\n",
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]\n",
    "data = pd.DataFrame(b)\n",
    "print(data)\n",
    "# Each sublist is represented as a row.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Rename the data frame columns based on the names in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score 1  Score 2  Score 3  Score 4  Score 5\n",
      "0     53.1     95.0     67.5     35.0     78.4\n",
      "1     61.3     40.8     30.8     37.8     87.6\n",
      "2     20.6     73.2     44.2     14.6     91.8\n",
      "3     57.4      0.1     96.1      4.2     69.5\n",
      "4     83.6     20.5     85.4     22.8     35.9\n",
      "5     49.0     69.0      0.1     31.8     89.1\n",
      "6     23.3     40.7     95.0     83.8     26.9\n",
      "7     27.6     26.4     53.8     88.8     68.5\n",
      "8     96.6     96.4     53.4     72.4     50.1\n",
      "9     73.7     39.0     43.2     81.6     34.7 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renames the data frame columns based on the names Im guessing (they were not provided).\n",
    "data = pd.DataFrame(b)\n",
    "data.columns = [\"Score 1\", \"Score 2\", \"Score 3\", \"Score 4\", \"Score 5\"]\n",
    "\n",
    "# Prints the data frame to see what it looks like.\n",
    "print(data, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a subset of this data frame that contains only the Score 1, 3, and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Score 1  Score 2  Score 3  Score 4  Score 5\n",
      "0     53.1     95.0     67.5     35.0     78.4\n",
      "1     61.3     40.8     30.8     37.8     87.6\n",
      "2     20.6     73.2     44.2     14.6     91.8\n",
      "3     57.4      0.1     96.1      4.2     69.5\n",
      "4     83.6     20.5     85.4     22.8     35.9\n",
      "5     49.0     69.0      0.1     31.8     89.1\n",
      "6     23.3     40.7     95.0     83.8     26.9\n",
      "7     27.6     26.4     53.8     88.8     68.5\n",
      "8     96.6     96.4     53.4     72.4     50.1\n",
      "9     73.7     39.0     43.2     81.6     34.7\n",
      "Subset DataFrame\n",
      "   Score 1  Score 3  Score 5\n",
      "0     53.1     67.5     78.4\n",
      "1     61.3     30.8     87.6\n",
      "2     20.6     44.2     91.8\n",
      "3     57.4     96.1     69.5\n",
      "4     83.6     85.4     35.9\n",
      "5     49.0      0.1     89.1\n",
      "6     23.3     95.0     26.9\n",
      "7     27.6     53.8     68.5\n",
      "8     96.6     53.4     50.1\n",
      "9     73.7     43.2     34.7\n"
     ]
    }
   ],
   "source": [
    "# Creates a subset of the data frame that contains only the Score 1, 3 and 5 columns.\n",
    "# Selects only columns 1, 3 and 5 (and their corresponding data) for the subset called data_subset.\n",
    "data_subset = data.iloc[:, [0,2,4]]\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)\n",
    "\n",
    "print(\"Subset DataFrame\")\n",
    "print(data_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. From the original data frame, calculate the average Score_3 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.95000000000001\n"
     ]
    }
   ],
   "source": [
    "# Calculates the average Score 3 value.\n",
    "score3_mean = data_subset[\"Score 3\"].mean()\n",
    "print(score3_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. From the original data frame, calculate the maximum Score_4 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.8\n"
     ]
    }
   ],
   "source": [
    "# Calculates the maximum Score 4 value from the original data frame.\n",
    "score4_max = data[\"Score 4\"].max()\n",
    "print(score4_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. From the original data frame, calculate the median Score 2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.75\n"
     ]
    }
   ],
   "source": [
    "score2_median = data[\"Score 2\"].median()\n",
    "print(score2_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create a Pandas DataFrame from the dictionary of product orders below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {'Description': ['LUNCH BAG APPLE DESIGN',\n",
    "  'SET OF 60 VINTAGE LEAF CAKE CASES ',\n",
    "  'RIBBON REEL STRIPES DESIGN ',\n",
    "  'WORLD WAR 2 GLIDERS ASSTD DESIGNS',\n",
    "  'PLAYING CARDS JUBILEE UNION JACK',\n",
    "  'POPCORN HOLDER',\n",
    "  'BOX OF VINTAGE ALPHABET BLOCKS',\n",
    "  'PARTY BUNTING',\n",
    "  'JAZZ HEARTS ADDRESS BOOK',\n",
    "  'SET OF 4 SANTA PLACE SETTINGS'],\n",
    " 'Quantity': [1, 24, 1, 2880, 2, 7, 1, 4, 10, 48],\n",
    " 'UnitPrice': [1.65, 0.55, 1.65, 0.18, 1.25, 0.85, 11.95, 4.95, 0.19, 1.25],\n",
    " 'Revenue': [1.65, 13.2, 1.65, 518.4, 2.5, 5.95, 11.95, 19.8, 1.9, 60.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Description  Quantity  UnitPrice  Revenue\n",
      "0              LUNCH BAG APPLE DESIGN         1       1.65     1.65\n",
      "1  SET OF 60 VINTAGE LEAF CAKE CASES         24       0.55    13.20\n",
      "2         RIBBON REEL STRIPES DESIGN          1       1.65     1.65\n",
      "3   WORLD WAR 2 GLIDERS ASSTD DESIGNS      2880       0.18   518.40\n",
      "4    PLAYING CARDS JUBILEE UNION JACK         2       1.25     2.50\n",
      "5                      POPCORN HOLDER         7       0.85     5.95\n",
      "6      BOX OF VINTAGE ALPHABET BLOCKS         1      11.95    11.95\n",
      "7                       PARTY BUNTING         4       4.95    19.80\n",
      "8            JAZZ HEARTS ADDRESS BOOK        10       0.19     1.90\n",
      "9       SET OF 4 SANTA PLACE SETTINGS        48       1.25    60.00\n"
     ]
    }
   ],
   "source": [
    "# Creates a pandas data frame from the dictionary of products.\n",
    "orders = {'Description': ['LUNCH BAG APPLE DESIGN',\n",
    "  'SET OF 60 VINTAGE LEAF CAKE CASES ',\n",
    "  'RIBBON REEL STRIPES DESIGN ',\n",
    "  'WORLD WAR 2 GLIDERS ASSTD DESIGNS',\n",
    "  'PLAYING CARDS JUBILEE UNION JACK',\n",
    "  'POPCORN HOLDER',\n",
    "  'BOX OF VINTAGE ALPHABET BLOCKS',\n",
    "  'PARTY BUNTING',\n",
    "  'JAZZ HEARTS ADDRESS BOOK',\n",
    "  'SET OF 4 SANTA PLACE SETTINGS'],\n",
    " 'Quantity': [1, 24, 1, 2880, 2, 7, 1, 4, 10, 48],\n",
    " 'UnitPrice': [1.65, 0.55, 1.65, 0.18, 1.25, 0.85, 11.95, 4.95, 0.19, 1.25],\n",
    " 'Revenue': [1.65, 13.2, 1.65, 518.4, 2.5, 5.95, 11.95, 19.8, 1.9, 60.0]}\n",
    "\n",
    "# Creates the data frame and displays its contents.\n",
    "products = pd.DataFrame(orders)\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calculate the total quantity ordered and revenue generated from these orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total quantity ordered is: 2978\n",
      "The total revenue generated by these orders is: 637.0\n"
     ]
    }
   ],
   "source": [
    "# Calculates the total quantity ordered and the revenue generated from these orders.\n",
    "total_quantity = products[\"Quantity\"].sum()\n",
    "revenue = products[\"Revenue\"].sum()\n",
    "\n",
    "print(f\"The total quantity ordered is: {total_quantity}\")\n",
    "print(f\"The total revenue generated by these orders is: {revenue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Obtain the prices of the most expensive and least expensive items ordered and print the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most expensive product costs 11.95\n",
      "The lease expensive product costs 0.18\n"
     ]
    }
   ],
   "source": [
    "# Obtains the prices of the most and least expensive items, and prints the difference.\n",
    "most_expensive = products[\"UnitPrice\"].max()\n",
    "least_expensive = products[\"UnitPrice\"].min()\n",
    "\n",
    "print(f\"The most expensive product costs {most_expensive}\")\n",
    "print(f\"The lease expensive product costs {least_expensive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load another dataset for more exercisesº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "admissions = pd.read_csv('../Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the dataset by looking at the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial No.             int64\n",
      "GRE Score              int64\n",
      "TOEFL Score            int64\n",
      "University Rating      int64\n",
      "SOP                  float64\n",
      "LOR                  float64\n",
      "CGPA                 float64\n",
      "Research               int64\n",
      "Chance of Admit      float64\n",
      "dtype: object\n",
      "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "0           1        337          118                  4  4.5   4.5  9.65   \n",
      "1           2        316          104                  3  3.0   3.5  8.00   \n",
      "2           3        322          110                  3  3.5   2.5  8.67   \n",
      "3           4        314          103                  2  2.0   3.0  8.21   \n",
      "4           5        330          115                  5  4.5   3.0  9.34   \n",
      "\n",
      "   Research  Chance of Admit   \n",
      "0         1              0.92  \n",
      "1         1              0.72  \n",
      "2         1              0.80  \n",
      "3         0              0.65  \n",
      "4         1              0.90  \n"
     ]
    }
   ],
   "source": [
    "# Evaluates the dataset by using the head function.\n",
    "# This will allow evaluation of the first 5 records in the data frame.\n",
    "print(admissions.dtypes)\n",
    "\n",
    "print(admissions.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Before beginning to work with this dataset and evaluating graduate admissions data, we will verify that there is no missing data in the dataset. Do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Serial No.  GRE Score  TOEFL Score  University Rating    SOP   LOR   \\\n",
      "0         False      False        False              False  False  False   \n",
      "1         False      False        False              False  False  False   \n",
      "2         False      False        False              False  False  False   \n",
      "3         False      False        False              False  False  False   \n",
      "4         False      False        False              False  False  False   \n",
      "..          ...        ...          ...                ...    ...    ...   \n",
      "380       False      False        False              False  False  False   \n",
      "381       False      False        False              False  False  False   \n",
      "382       False      False        False              False  False  False   \n",
      "383       False      False        False              False  False  False   \n",
      "384       False      False        False              False  False  False   \n",
      "\n",
      "      CGPA  Research  Chance of Admit   \n",
      "0    False     False             False  \n",
      "1    False     False             False  \n",
      "2    False     False             False  \n",
      "3    False     False             False  \n",
      "4    False     False             False  \n",
      "..     ...       ...               ...  \n",
      "380  False     False             False  \n",
      "381  False     False             False  \n",
      "382  False     False             False  \n",
      "383  False     False             False  \n",
      "384  False     False             False  \n",
      "\n",
      "[385 rows x 9 columns]\n",
      "There are missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Verifies that there is no missing data in the dataset.\n",
    "missing_eval = admissions.isnull()\n",
    "\n",
    "# Gives a preview of the dataset for a visual examination.\n",
    "print(missing_eval)\n",
    "\n",
    "# Determines if there are any missing values in the dataset to notify accordingly.\n",
    "if missing_eval.all == \"False\":\n",
    "    print(\"There is no missing data in the dataset.\")\n",
    "else:\n",
    "    print(\"There are missing values in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2 -  Interestingly, there is a column that uniquely identifies the applicants. This column is the serial number column. Instead of having our own index, we should make this column our index. Do this in the cell below. Keep the column in the dataframe in addition to making it an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "Serial No.                                                               \n",
      "1                 337          118                  4  4.5   4.5  9.65   \n",
      "2                 316          104                  3  3.0   3.5  8.00   \n",
      "3                 322          110                  3  3.5   2.5  8.67   \n",
      "4                 314          103                  2  2.0   3.0  8.21   \n",
      "5                 330          115                  5  4.5   3.0  9.34   \n",
      "...               ...          ...                ...  ...   ...   ...   \n",
      "381               324          110                  3  3.5   3.5  9.04   \n",
      "382               325          107                  3  3.0   3.5  9.11   \n",
      "383               330          116                  4  5.0   4.5  9.45   \n",
      "384               312          103                  3  3.5   4.0  8.78   \n",
      "385               333          117                  4  5.0   4.0  9.66   \n",
      "\n",
      "            Research  Chance of Admit   \n",
      "Serial No.                              \n",
      "1                  1              0.92  \n",
      "2                  1              0.72  \n",
      "3                  1              0.80  \n",
      "4                  0              0.65  \n",
      "5                  1              0.90  \n",
      "...              ...               ...  \n",
      "381                1              0.82  \n",
      "382                1              0.84  \n",
      "383                1              0.91  \n",
      "384                0              0.67  \n",
      "385                1              0.95  \n",
      "\n",
      "[385 rows x 8 columns]\n",
      "GRE Score              int64\n",
      "TOEFL Score            int64\n",
      "University Rating      int64\n",
      "SOP                  float64\n",
      "LOR                  float64\n",
      "CGPA                 float64\n",
      "Research               int64\n",
      "Chance of Admit      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creates an index from the serial number column, keeping the serial number column as well.\n",
    "admissions.set_index(\"Serial No.\", inplace = True)\n",
    "\n",
    "print(admissions)\n",
    "\n",
    "print(admissions.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that `GRE Score` and `CGPA` also uniquely identify the data. Show this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "Serial No.                                                               \n",
      "1                 337          118                  4  4.5   4.5  9.65   \n",
      "2                 316          104                  3  3.0   3.5  8.00   \n",
      "3                 322          110                  3  3.5   2.5  8.67   \n",
      "4                 314          103                  2  2.0   3.0  8.21   \n",
      "5                 330          115                  5  4.5   3.0  9.34   \n",
      "...               ...          ...                ...  ...   ...   ...   \n",
      "381               324          110                  3  3.5   3.5  9.04   \n",
      "382               325          107                  3  3.0   3.5  9.11   \n",
      "383               330          116                  4  5.0   4.5  9.45   \n",
      "384               312          103                  3  3.5   4.0  8.78   \n",
      "385               333          117                  4  5.0   4.0  9.66   \n",
      "\n",
      "            Research  Chance of Admit   \n",
      "Serial No.                              \n",
      "1                  1              0.92  \n",
      "2                  1              0.72  \n",
      "3                  1              0.80  \n",
      "4                  0              0.65  \n",
      "5                  1              0.90  \n",
      "...              ...               ...  \n",
      "381                1              0.82  \n",
      "382                1              0.84  \n",
      "383                1              0.91  \n",
      "384                0              0.67  \n",
      "385                1              0.95  \n",
      "\n",
      "[385 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Adds GRE Score and CGPA as index in addition to Serial number.\n",
    "# It first resets the data frame to its original condition in terms of index,\n",
    "# and then sets all 3 columns as index.\n",
    "#admissions.reset_index(inplace = True)\n",
    "#admissions.set_index([\"Serial No.\",\"GRE Score\", \"CGPA\"], inplace = True)\n",
    "\n",
    "new_index = pd.Index([\"Serial No.\", \"GRE Score\", \"CGPA\"])\n",
    "print(admissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - In this part of the lab, we would like to test complex conditions on the entire data set at once. Let's start by finding the number of rows where the CGPA is greater than 9 and the student has performed an investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "            GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "Serial No.                                                               \n",
      "1                 337          118                  4  4.5   4.5  9.65   \n",
      "2                 316          104                  3  3.0   3.5  8.00   \n",
      "3                 322          110                  3  3.5   2.5  8.67   \n",
      "4                 314          103                  2  2.0   3.0  8.21   \n",
      "5                 330          115                  5  4.5   3.0  9.34   \n",
      "\n",
      "            Research  Chance of Admit   \n",
      "Serial No.                              \n",
      "1                  1              0.92  \n",
      "2                  1              0.72  \n",
      "3                  1              0.80  \n",
      "4                  0              0.65  \n",
      "5                  1              0.90  \n"
     ]
    }
   ],
   "source": [
    "# Finds the number of rows where the CGPA is greater than 9 and the\n",
    "# student has performed an investigation.\n",
    "\n",
    "# Initialize a counter for students meeting the criteria\n",
    "count_test_1 = 0\n",
    "\n",
    "# Iterate through each student in the admissions DataFrame\n",
    "for index, student in admissions.iterrows(): \n",
    "    # Check the condition for each student individually\n",
    "    if (student[\"CGPA\"] > 9) and (student[\"Research\"] == 1):\n",
    "        count_test_1 += 1  # Increment the counter for this student\n",
    "\n",
    "# Print the result\n",
    "print(count_test_1)\n",
    "\n",
    "# Optionally, if you want to see the original DataFrame without modifications\n",
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Now return all the rows where the CGPA is greater than 9 and the SOP score is less than 3.5. Find the mean chance of admit for these applicants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial No.  GRE Score  TOEFL score  University Rating  SOP  LOR  CGPA  \\\n",
      "0           1        320          110                  5  4.5  4.0   9.1   \n",
      "1           2        310          105                  4  3.0  3.5   8.5   \n",
      "2           3        300          100                  3  2.5  3.0   9.5   \n",
      "\n",
      "   Chance of Admit  \n",
      "0             0.90  \n",
      "1             0.70  \n",
      "2             0.95  \n",
      "There are 1 students that meet these requirements.\n",
      "   Serial No.  GRE Score  TOEFL score  University Rating  SOP  LOR  CGPA  \\\n",
      "0           1        320          110                  5  4.5  4.0   9.1   \n",
      "1           2        310          105                  4  3.0  3.5   8.5   \n",
      "2           3        300          100                  3  2.5  3.0   9.5   \n",
      "\n",
      "   Chance of Admit  Test 2  \n",
      "0             0.90       0  \n",
      "1             0.70       0  \n",
      "2             0.95       1  \n",
      "The mean chance for those records that meet this test is 0.95\n"
     ]
    }
   ],
   "source": [
    "# Returns all the rows where the CGPA is greater than 9 and the SOP score is less than 3.5.\n",
    "# Finds the mean chance of admit for these applicants.\n",
    "\n",
    "data = {\n",
    "    \"Serial No.\": [1, 2, 3],\n",
    "    \"GRE Score\": [320, 310, 300],\n",
    "    \"TOEFL score\": [110, 105, 100],\n",
    "    \"University Rating\": [5, 4, 3],\n",
    "    \"SOP\": [4.5, 3.0, 2.5],\n",
    "    \"LOR\": [4.0, 3.5, 3.0],\n",
    "    \"CGPA\": [9.1, 8.5, 9.5],\n",
    "    \"Chance of Admit\": [0.9, 0.7, 0.95]  # Sample column for chance of admit\n",
    "}\n",
    "\n",
    "# Define admissions as a DataFrame\n",
    "admissions = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(admissions.head())\n",
    "\n",
    "# Initialize the 'Test 2' column\n",
    "admissions[\"Test 2\"] = 0\n",
    "\n",
    "# Iterate through each student in the admissions DataFrame\n",
    "for index, student in admissions.iterrows(): \n",
    "    # Check the condition for each student individually\n",
    "    if (student[\"CGPA\"] > 9) and (student[\"SOP\"] < 3.5):\n",
    "        admissions.at[index, \"Test 2\"] = 1  # Set Test 2 to 1 for this student\n",
    "    else:\n",
    "        admissions.at[index, \"Test 2\"] = 0  # Set Test 2 to 0 for this student\n",
    "\n",
    "result2 = admissions[\"Test 2\"].sum()  # Sum the values in the Test 2 column\n",
    "print(f\"There are {result2} students that meet these requirements.\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(admissions.head())\n",
    "\n",
    "# Calculate the mean chance of admit for these applicants.\n",
    "# Add the Chance of Admit column for the students that meet Test 2.\n",
    "if \"Chance of Admit\" in admissions.columns:\n",
    "    sum_chance = 0\n",
    "\n",
    "    for index, student in admissions.iterrows():\n",
    "        if (student[\"Test 2\"] == 1):\n",
    "            sum_chance += student[\"Chance of Admit\"]  \n",
    "\n",
    "    mean_chance = sum_chance / result2 if result2 > 0 else 0  \n",
    "    print(f\"The mean chance for those records that meet this test is {mean_chance}\")\n",
    "    \n",
    "else:\n",
    "    print(\"The column 'Chance of Admit' does not exist in the DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
