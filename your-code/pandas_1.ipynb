{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas Lab\n",
    "\n",
    "Complete the following set of exercises to solidify your knowledge of Pandas fundamentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Numpy and Pandas and alias them to `np` and `pd` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a Pandas Series containing the elements of the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [5.7, 75.2, 74.4, 84.0, 66.5, 66.3, 55.8, 75.7, 29.1, 43.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5.7\n",
      "1    75.2\n",
      "2    74.4\n",
      "3    84.0\n",
      "4    66.5\n",
      "5    66.3\n",
      "6    55.8\n",
      "7    75.7\n",
      "8    29.1\n",
      "9    43.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "series = pd.Series(lst) # Create a Pandas series\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use indexing to return the third value in the Series above.\n",
    "\n",
    "*Hint: Remember that indexing begins at 0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The third value is 74.4\n"
     ]
    }
   ],
   "source": [
    "third_value = series[2] # access the third value in the series\n",
    "print(f\"The third value is {third_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a Pandas DataFrame from the list of lists below. Each sublist should be represented as a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4\n",
      "0  53.1  95.0  67.5  35.0  78.4\n",
      "1  61.3  40.8  30.8  37.8  87.6\n",
      "2  20.6  73.2  44.2  14.6  91.8\n",
      "3  57.4   0.1  96.1   4.2  69.5\n",
      "4  83.6  20.5  85.4  22.8  35.9\n",
      "5  49.0  69.0   0.1  31.8  89.1\n",
      "6  23.3  40.7  95.0  83.8  26.9\n",
      "7  27.6  26.4  53.8  88.8  68.5\n",
      "8  96.6  96.4  53.4  72.4  50.1\n",
      "9  73.7  39.0  43.2  81.6  34.7\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(b) # create the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Rename the data frame columns based on the names in the list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[53.1, 95.0, 67.5, 35.0, 78.4],\n",
    "     [61.3, 40.8, 30.8, 37.8, 87.6],\n",
    "     [20.6, 73.2, 44.2, 14.6, 91.8],\n",
    "     [57.4, 0.1, 96.1, 4.2, 69.5],\n",
    "     [83.6, 20.5, 85.4, 22.8, 35.9],\n",
    "     [49.0, 69.0, 0.1, 31.8, 89.1],\n",
    "     [23.3, 40.7, 95.0, 83.8, 26.9],\n",
    "     [27.6, 26.4, 53.8, 88.8, 68.5],\n",
    "     [96.6, 96.4, 53.4, 72.4, 50.1],\n",
    "     [73.7, 39.0, 43.2, 81.6, 34.7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score_1  Score_2  Score_3  Score_4  Score_5\n",
      "0     53.1     95.0     67.5     35.0     78.4\n",
      "1     61.3     40.8     30.8     37.8     87.6\n",
      "2     20.6     73.2     44.2     14.6     91.8\n",
      "3     57.4      0.1     96.1      4.2     69.5\n",
      "4     83.6     20.5     85.4     22.8     35.9\n",
      "5     49.0     69.0      0.1     31.8     89.1\n",
      "6     23.3     40.7     95.0     83.8     26.9\n",
      "7     27.6     26.4     53.8     88.8     68.5\n",
      "8     96.6     96.4     53.4     72.4     50.1\n",
      "9     73.7     39.0     43.2     81.6     34.7\n"
     ]
    }
   ],
   "source": [
    "column_names = ['Score_1','Score_2','Score_3','Score_4','Score_5']\n",
    "\n",
    "df.columns = column_names # renaming the columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a subset of this data frame that contains only the Score 1, 3, and 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score_1  Score_3  Score_5\n",
      "0     53.1     67.5     78.4\n",
      "1     61.3     30.8     87.6\n",
      "2     20.6     44.2     91.8\n",
      "3     57.4     96.1     69.5\n",
      "4     83.6     85.4     35.9\n",
      "5     49.0      0.1     89.1\n",
      "6     23.3     95.0     26.9\n",
      "7     27.6     53.8     68.5\n",
      "8     96.6     53.4     50.1\n",
      "9     73.7     43.2     34.7\n"
     ]
    }
   ],
   "source": [
    "# subset_df = df.iloc[:, [0,2,4]] # select columns by index\n",
    "subset_df = df[['Score_1','Score_3','Score_5']] # create a subset by columns names\n",
    "\n",
    "print(subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. From the original data frame, calculate the average Score_3 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of Score_3 column is: 56.95000000000001\n"
     ]
    }
   ],
   "source": [
    "# average_score_3 = df[2].mean()\n",
    "average_score_3 = df['Score_3'].mean()\n",
    "print(f\"The average Score_3 value is: {average_score_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. From the original data frame, calculate the maximum Score_4 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximun Score_4 value is: 88.8\n"
     ]
    }
   ],
   "source": [
    "# max_score_4 = df[3].mean()\n",
    "max_score_4 = df['Score_4'].max()\n",
    "print(f\"The maximun Score_4 value is: {max_score_4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. From the original data frame, calculate the median Score 2 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median Score_2 value is: 40.75\n"
     ]
    }
   ],
   "source": [
    "# meadian_score_2 = df[1].median()\n",
    "meadian_score_2 = df['Score_2'].median()\n",
    "print(f\"The median Score_2 value is: {meadian_score_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Create a Pandas DataFrame from the dictionary of product orders below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = {'Description': ['LUNCH BAG APPLE DESIGN',\n",
    "  'SET OF 60 VINTAGE LEAF CAKE CASES ',\n",
    "  'RIBBON REEL STRIPES DESIGN ',\n",
    "  'WORLD WAR 2 GLIDERS ASSTD DESIGNS',\n",
    "  'PLAYING CARDS JUBILEE UNION JACK',\n",
    "  'POPCORN HOLDER',\n",
    "  'BOX OF VINTAGE ALPHABET BLOCKS',\n",
    "  'PARTY BUNTING',\n",
    "  'JAZZ HEARTS ADDRESS BOOK',\n",
    "  'SET OF 4 SANTA PLACE SETTINGS'],\n",
    " 'Quantity': [1, 24, 1, 2880, 2, 7, 1, 4, 10, 48],\n",
    " 'UnitPrice': [1.65, 0.55, 1.65, 0.18, 1.25, 0.85, 11.95, 4.95, 0.19, 1.25],\n",
    " 'Revenue': [1.65, 13.2, 1.65, 518.4, 2.5, 5.95, 11.95, 19.8, 1.9, 60.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders DataFrame:\n",
      "                          Description  Quantity  UnitPrice  Revenue\n",
      "0              LUNCH BAG APPLE DESIGN         1       1.65     1.65\n",
      "1  SET OF 60 VINTAGE LEAF CAKE CASES         24       0.55    13.20\n",
      "2         RIBBON REEL STRIPES DESIGN          1       1.65     1.65\n",
      "3   WORLD WAR 2 GLIDERS ASSTD DESIGNS      2880       0.18   518.40\n",
      "4    PLAYING CARDS JUBILEE UNION JACK         2       1.25     2.50\n",
      "5                      POPCORN HOLDER         7       0.85     5.95\n",
      "6      BOX OF VINTAGE ALPHABET BLOCKS         1      11.95    11.95\n",
      "7                       PARTY BUNTING         4       4.95    19.80\n",
      "8            JAZZ HEARTS ADDRESS BOOK        10       0.19     1.90\n",
      "9       SET OF 4 SANTA PLACE SETTINGS        48       1.25    60.00\n"
     ]
    }
   ],
   "source": [
    "orders_df = pd.DataFrame(orders)\n",
    "print(\"Orders DataFrame:\")\n",
    "print(orders_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calculate the total quantity ordered and revenue generated from these orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total quantity ordered is: 2978\n",
      "The total revenue generated is: 637.0\n"
     ]
    }
   ],
   "source": [
    "total_quantity = orders_df['Quantity'].sum()\n",
    "total_revenue = orders_df['Revenue'].sum()\n",
    "\n",
    "print(f\"The total quantity ordered is: {total_quantity}\")\n",
    "print(f\"The total revenue generated is: {total_revenue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Obtain the prices of the most expensive and least expensive items ordered and print the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difference between most 11.95 and least 0.18 expensive prices is 11.77\n"
     ]
    }
   ],
   "source": [
    "most_expensive = orders_df['UnitPrice'].max()\n",
    "least_expensive = orders_df['UnitPrice'].min()\n",
    "\n",
    "difference = most_expensive - least_expensive\n",
    "\n",
    "print(f\"The difference between most {most_expensive} and least {least_expensive} expensive prices is {difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load another dataset for more exercisesÂº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "admissions = pd.read_csv('../Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the dataset by looking at the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
      "0           1        337          118                  4  4.5   4.5  9.65   \n",
      "1           2        316          104                  3  3.0   3.5  8.00   \n",
      "2           3        322          110                  3  3.5   2.5  8.67   \n",
      "3           4        314          103                  2  2.0   3.0  8.21   \n",
      "4           5        330          115                  5  4.5   3.0  9.34   \n",
      "\n",
      "   Research  Chance of Admit   \n",
      "0         1              0.92  \n",
      "1         1              0.72  \n",
      "2         1              0.80  \n",
      "3         0              0.65  \n",
      "4         1              0.90  \n"
     ]
    }
   ],
   "source": [
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Before beginning to work with this dataset and evaluating graduate admissions data, we will verify that there is no missing data in the dataset. Do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values in Each Column:\n",
      " Serial No.           0\n",
      "GRE Score            0\n",
      "TOEFL Score          0\n",
      "University Rating    0\n",
      "SOP                  0\n",
      "LOR                  0\n",
      "CGPA                 0\n",
      "Research             0\n",
      "Chance of Admit      0\n",
      "dtype: int64\n",
      "\n",
      "Number of Columns with Missing Values: 0\n",
      "All Columns Have Missing Values: False\n",
      "\n",
      "Total Missing Values in the DataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "admissions_df = pd.DataFrame(admissions)\n",
    "\n",
    "# Check for missing values in the DataFrame\n",
    "missing_values = pd.isnull(admissions_df)\n",
    "\n",
    "# Count missing values in each column\n",
    "missing_counts = missing_values.sum()\n",
    "\n",
    "# Count columns with missing values\n",
    "columns_with_missing = missing_counts[missing_counts > 0].count()\n",
    "\n",
    "# Check if all columns have missing values\n",
    "all_columns_missing = missing_counts.all()\n",
    "\n",
    "# Calculate the total number of missing values\n",
    "total_missing_values = missing_counts.sum()\n",
    "\n",
    "# Display the results\n",
    "print(\"Missing Values in Each Column:\\n\", missing_counts)\n",
    "print(\"\\nNumber of Columns with Missing Values:\", columns_with_missing)\n",
    "print(\"All Columns Have Missing Values:\", all_columns_missing)\n",
    "print(\"\\nTotal Missing Values in the DataFrame:\", total_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2 -  Interestingly, there is a column that uniquely identifies the applicants. This column is the serial number column. Instead of having our own index, we should make this column our index. Do this in the cell below. Keep the column in the dataframe in addition to making it an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   \\\n",
      "Serial No.                                                                     \n",
      "1                    1        337          118                  4  4.5   4.5   \n",
      "2                    2        316          104                  3  3.0   3.5   \n",
      "3                    3        322          110                  3  3.5   2.5   \n",
      "4                    4        314          103                  2  2.0   3.0   \n",
      "5                    5        330          115                  5  4.5   3.0   \n",
      "\n",
      "            CGPA  Research  Chance of Admit   \n",
      "Serial No.                                    \n",
      "1           9.65         1              0.92  \n",
      "2           8.00         1              0.72  \n",
      "3           8.67         1              0.80  \n",
      "4           8.21         0              0.65  \n",
      "5           9.34         1              0.90  \n"
     ]
    }
   ],
   "source": [
    "admissions_df = admissions_df.set_index('Serial No.', drop=False) # Set 'Serial No.' as the index \n",
    "print(admissions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that `GRE Score` and `CGPA` also uniquely identify the data. Show this in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - In this part of the lab, we would like to test complex conditions on the entire data set at once. Let's start by finding the number of rows where the CGPA is greater than 9 and the student has performed an investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows where CGPA > 9 and the student has performed research is 101\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where CGPA > 9 and Research = 1\n",
    "filtered_rows_df = admissions_df[(admissions_df['CGPA'] > 9) & (admissions_df['Research'] == 1)]\n",
    "\n",
    "# Count the number of rows\n",
    "number_of_rows = filtered_rows_df.shape[0]\n",
    "\n",
    "# Display the result\n",
    "print(f\"The number of rows where CGPA > 9 and the student has performed research is {number_of_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Now return all the rows where the CGPA is greater than 9 and the SOP score is less than 3.5. Find the mean chance of admit for these applicants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
      "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
      "      dtype='object')\n",
      "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
      "       'LOR', 'CGPA', 'Research', 'Chance of Admit'],\n",
      "      dtype='object')\n",
      "\n",
      "Rows in selection: 5\n",
      "The mean chance of adminit for students where CGPA > 9 and SOP < 3.5 is 0.80\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where CGPA > 9 and SOP < 3.5\n",
    "filtered_rows_df = admissions_df[(admissions_df['CGPA'] > 9) & (admissions_df['SOP'] < 3.5)]\n",
    "\n",
    "print(filtered_rows_df.columns) # Check the real name of the column 'Chance of Admit '\n",
    "filtered_rows_df.columns = admissions_df.columns.str.strip() # Remove spaces at the end\n",
    "print(filtered_rows_df.columns) # Check the real name of the column 'Chance of Admit '\n",
    "print()\n",
    "\n",
    "# Count the number of rows\n",
    "number_of_rows = filtered_rows_df.shape[0]\n",
    "# mean chance of admit for applications \n",
    "mean_chance_of_admit = filtered_rows_df['Chance of Admit'].mean()\n",
    "\n",
    "# Display the result\n",
    "print(f'Rows in selection: {number_of_rows}')\n",
    "print(f\"The mean chance of adminit for students where CGPA > 9 and SOP < 3.5 is {mean_chance_of_admit:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": "",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
